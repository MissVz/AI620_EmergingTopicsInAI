{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales Forecasting using DeepAR\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Prepare Train and Test Datasets](#Prepare-Train-and-Test-Datasets)\n",
    "3. [Model Training](#Model-Training)\n",
    "   1. [Define-Hyperparameters](#Define-Hyperparameters)\n",
    "   2. [Model Fitting](#Model-Fitting)\n",
    "4. [Deploy Trained Model](#Deploy-Trained-Model)\n",
    "5. [Consume Deployed Model](#Consume-Deployed-Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The [kaggle](https://www.kaggle.com/manjeetsingh/retaildataset) dataset contains historical sales for 45 stores, with each store belonging to a specific type (location and performance) and size. The retailer runs several promotional markdowns throughout the year. These markdowns precede holidays, such as SuperBowl, Labor Day, Thanksgiving, and Christmas.\n",
    "\n",
    "We will forecast category sales for store 20. Remember that in the previous notebook where we explored sales data, we saved sales of store 20 in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sagemaker.amazon.common as smac    \n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools==65.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (65.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install setuptools==65.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /home/ec2-user/SageMaker/notebooks\n",
      "Contents: ['Train_Sales_DeepAR.ipynb', 'retailsales.csv', 'EDA_RetailSales.ipynb', '.ipynb_checkpoints']\n"
     ]
    }
   ],
   "source": [
    "# Print current working directory\n",
    "print(\"Current Directory:\", os.getcwd())\n",
    "\n",
    "# List files in the current directory\n",
    "print(\"Contents:\", os.listdir(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Navigation Current Directory: /home/ec2-user/SageMaker\n",
      "Contents of Project Root Directory: ['notebooks', 'data', 'lost+found', '.virtual_documents', 'README.md', '.sparkmagic', 'build', 'deepar_sales_training.json', 'setup.py', 'deepar', 'deepar_sales_test.json', 'deepar.egg-info', '.ipynb_checkpoints']\n",
      "Processing /home/ec2-user/SageMaker\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: deepar\n",
      "  Building wheel for deepar (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for deepar: filename=deepar-0.0.0-py3-none-any.whl size=3441 sha256=352c19286d532296904d4dbf405bde9bf26406b9542b925b71f2d2b3406db652\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7ujtnhvr/wheels/79/a2/86/f30415f29cd2ece5ccbccf03b1ed8d9cb848afeabedfec49df\n",
      "Successfully built deepar\n",
      "Installing collected packages: deepar\n",
      "  Attempting uninstall: deepar\n",
      "    Found existing installation: deepar 0.0.0\n",
      "    Uninstalling deepar-0.0.0:\n",
      "      Successfully uninstalled deepar-0.0.0\n",
      "Successfully installed deepar-0.0.0\n"
     ]
    }
   ],
   "source": [
    "#Navidate to deep-ar directory to install the deepar package containing commonly used functions\n",
    "path = \"..\"  # Navigate up one level to access setup.py\n",
    "os.chdir(path)\n",
    "\n",
    "# Verify the directory contains setup.py\n",
    "print(\"After Navigation Current Directory:\", os.getcwd())\n",
    "print(\"Contents of Project Root Directory:\", os.listdir())\n",
    "\n",
    "#install predefined functions\n",
    "!pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker\n"
     ]
    }
   ],
   "source": [
    "#Navigate to the parent directory to train the DeepAR model\n",
    "# org_path = \"..\"\n",
    "# os.chdir(org_path)\n",
    "\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import deepar as da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Train and Test Datasets\n",
    "The datasets should be in JSON Lines format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_key      = 'deepar_sales_training.json'\n",
    "test_key       = 'deepar_sales_test.json'\n",
    "#Prediction and context length for training the DeepAR model\n",
    "prediction_length = 9\n",
    "salesfn = 'data/store20_sales.csv'\n",
    "\n",
    "salesdf = da.retailsales.prepareSalesData(salesfn)\n",
    "testSet = da.retailsales.getTestSales(salesdf, test_key)\n",
    "trainingSet = da.retailsales.getTrainSales(salesdf, train_key, prediction_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We have only looked at store 20 sales. However, you can train on all store sales by including store number in the category list - for each series in train and test sets, include \"cat\": [department number, store number]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Input data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "import boto3\n",
    "\n",
    "bucket         = 'pe09'\n",
    "prefix         = 'deepar-weekly-sales'\n",
    "\n",
    "train_prefix   = '{}/{}'.format(prefix, 'train')\n",
    "test_prefix    = '{}/{}'.format(prefix, 'test')\n",
    "output_prefix  = '{}/{}'.format(prefix, 'output')\n",
    "\n",
    "# Update the session to match the S3 bucket region\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto3.Session(region_name=\"us-east-2\"))\n",
    "\n",
    "train_path = sagemaker_session.upload_data(train_key, bucket=bucket, key_prefix=train_prefix)\n",
    "test_path = sagemaker_session.upload_data(test_key, bucket=bucket, key_prefix=test_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Same images used for training and inference. Defaulting to image scope: inference.\n",
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: 1.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "WARNING:sagemaker.deprecations:train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "WARNING:sagemaker.deprecations:train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "role = get_execution_role()\n",
    "output_path = r's3://{0}/{1}'.format(bucket, output_prefix) \n",
    "\n",
    "# container = get_image_uri(boto3.Session().region_name, 'forecasting-deepar')\n",
    "# Retrieve the container URI for DeepAR in the us-east-2 region\n",
    "container = retrieve(\"forecasting-deepar\", region=\"us-east-2\")\n",
    "\n",
    "deepAR = sagemaker.estimator.Estimator(container,\n",
    "                                   role,\n",
    "                                   train_instance_count=1,\n",
    "                                   train_instance_type='ml.c4.xlarge',\n",
    "                                   output_path=output_path,\n",
    "                                   sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"time_freq\": 'W', # weekly series\n",
    "    \"context_length\": prediction_length, # how many data points are we going to look at before predicting\n",
    "    \"prediction_length\": prediction_length, # number of data points to predict\n",
    "    \"num_cells\": \"40\", # of cells to use in each of the hidden layers\n",
    "    \"num_layers\": \"2\", # of hidden layers\n",
    "    \"likelihood\": \"gaussian\",\n",
    "    \"epochs\": \"300\", # max number of passses over the training data\n",
    "    \"mini_batch_size\": \"32\", # size of the mini batches used during training\n",
    "    \"learning_rate\": \"0.00001\",\n",
    "    \"dropout_rate\": \"0.05\", #for each iteration, a random subset of hidden neurons are not updated\n",
    "    \"early_stopping_patience\": \"10\" # stop if loss hasn't improved in 10 epochs\n",
    "}\n",
    "\n",
    "deepAR.set_hyperparameters(**hyperparameters) #** = arbitrary number of arguments to functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: forecasting-deepar-2024-12-07-01-37-36-780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-07 01:37:39 Starting - Starting the training job...\n",
      "2024-12-07 01:37:54 Starting - Preparing the instances for training...\n",
      "2024-12-07 01:38:40 Downloading - Downloading the training image..............\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34mRunning custom environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-input.json: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.10', 'early_stopping_patience': '', 'embedding_dimension': '10', 'learning_rate': '0.001', 'likelihood': 'student-t', 'mini_batch_size': '128', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]'}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'context_length': '9', 'dropout_rate': '0.05', 'early_stopping_patience': '10', 'epochs': '300', 'learning_rate': '0.00001', 'likelihood': 'gaussian', 'mini_batch_size': '32', 'num_cells': '40', 'num_layers': '2', 'prediction_length': '9', 'time_freq': 'W'}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] Final configuration: {'_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', 'cardinality': 'auto', 'dropout_rate': '0.05', 'early_stopping_patience': '10', 'embedding_dimension': '10', 'learning_rate': '0.00001', 'likelihood': 'gaussian', 'mini_batch_size': '32', 'num_cells': '40', 'num_dynamic_feat': 'auto', 'num_eval_samples': '100', 'num_layers': '2', 'test_quantiles': '[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', 'context_length': '9', 'epochs': '300', 'prediction_length': '9', 'time_freq': 'W'}\u001b[0m\n",
      "\u001b[34mProcess 8 is a worker.\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] Using early stopping with patience 10\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] random_seed is None\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/deepar_sales_training.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/deepar_sales_training.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] [cardinality=auto] Inferred value of cardinality=[66] from dataset.\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=1 from dataset.\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] Training set statistics:\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] Real time series\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] number of time series: 66\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] number of observations: 8844\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] mean target length: 134.0\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] min/mean/max target: 223.3000030517578/31660.356933372906/422306.25\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] mean abs(target): 31660.356933372906\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] contains missing values: no\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] Small number of time series. Doing 5 passes over dataset with prob 0.9696969696969697 per epoch.\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] Test set statistics:\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] Real time series\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] number of time series: 66\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] number of observations: 9438\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] mean target length: 143.0\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] min/mean/max target: 223.3000030517578/31667.61111662958/422306.25\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] mean abs(target): 31667.61111662958\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] contains missing values: no\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/algorithm/core/date_feature_set.py:44: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
      "  return index.weekofyear / 51.0 - 0.5\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] #memory_usage::<batchbuffer> = 0.89111328125 mb\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] nvidia-smi: took 0.031 seconds to run.\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535655.3330407, \"EndTime\": 1733535655.364195, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 30.225753784179688, \"count\": 1, \"min\": 30.225753784179688, \"max\": 30.225753784179688}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] #memory_usage::<model> = 3 mb\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535655.3642573, \"EndTime\": 1733535655.4097993, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 76.64728164672852, \"count\": 1, \"min\": 76.64728164672852, \"max\": 76.64728164672852}}}\u001b[0m\n",
      "\u001b[34m[01:40:55] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_Cuda_11.1.x.406.0/AL2_x86_64/generic-flavor/src/src/operator/nn/mkldnn/mkldnn_base.cc:74: Allocate 5120 bytes with malloc directly\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] Epoch[0] Batch[0] avg_epoch_loss=11.088387\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=11.088386535644531\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] Epoch[0] Batch[5] avg_epoch_loss=10.871599\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=10.871599038441977\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] Epoch[0] Batch [5]#011Speed: 1075.64 samples/sec#011loss=10.871599\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] processed a total of 317 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535655.4098675, \"EndTime\": 1733535655.8200579, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 300.0, \"count\": 1, \"min\": 300, \"max\": 300}, \"update.time\": {\"sum\": 410.10046005249023, \"count\": 1, \"min\": 410.10046005249023, \"max\": 410.10046005249023}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=772.7041610318573 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] #progress_metric: host=algo-1, completed 0.3333333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] #quality_metric: host=algo-1, epoch=0, train loss <loss>=10.852635478973388\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] Saved checkpoint to \"/opt/ml/model/state_2b40525f-4c9a-4fa6-b972-04285eec70f0-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535655.8201494, \"EndTime\": 1733535655.826965, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 6.227970123291016, \"count\": 1, \"min\": 6.227970123291016, \"max\": 6.227970123291016}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] Epoch[1] Batch[0] avg_epoch_loss=10.969873\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:55 INFO 140215349077824] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=10.969873428344727\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] Epoch[1] Batch[5] avg_epoch_loss=10.696340\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=10.696340401967367\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] Epoch[1] Batch [5]#011Speed: 1106.52 samples/sec#011loss=10.696340\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] Epoch[1] Batch[10] avg_epoch_loss=10.818411\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=10.964895439147949\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] Epoch[1] Batch [10]#011Speed: 1057.19 samples/sec#011loss=10.964895\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] processed a total of 334 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535655.8270147, \"EndTime\": 1733535656.233141, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 406.07762336730957, \"count\": 1, \"min\": 406.07762336730957, \"max\": 406.07762336730957}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=822.3087587277641 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] #progress_metric: host=algo-1, completed 0.6666666666666666 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] #quality_metric: host=algo-1, epoch=1, train loss <loss>=10.818410873413086\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] Saved checkpoint to \"/opt/ml/model/state_e68ccba1-aa43-4316-b649-b703818c4686-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535656.233197, \"EndTime\": 1733535656.2406785, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 7.1163177490234375, \"count\": 1, \"min\": 7.1163177490234375, \"max\": 7.1163177490234375}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] Epoch[2] Batch[0] avg_epoch_loss=10.757697\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=10.757697105407715\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] Epoch[2] Batch[5] avg_epoch_loss=10.971303\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=10.97130266825358\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] Epoch[2] Batch [5]#011Speed: 1079.67 samples/sec#011loss=10.971303\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] processed a total of 301 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535656.2407298, \"EndTime\": 1733535656.6211715, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 380.39112091064453, \"count\": 1, \"min\": 380.39112091064453, \"max\": 380.39112091064453}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=790.9061376273921 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] #progress_metric: host=algo-1, completed 1.0 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] #quality_metric: host=algo-1, epoch=2, train loss <loss>=10.850832557678222\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] Epoch[3] Batch[0] avg_epoch_loss=11.038125\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=11.038125038146973\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] Epoch[3] Batch[5] avg_epoch_loss=11.028414\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=11.028413931528727\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] Epoch[3] Batch [5]#011Speed: 1134.57 samples/sec#011loss=11.028414\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] processed a total of 315 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535656.6213222, \"EndTime\": 1733535656.992203, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 370.3937530517578, \"count\": 1, \"min\": 370.3937530517578, \"max\": 370.3937530517578}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=850.2033220333748 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] #progress_metric: host=algo-1, completed 1.3333333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] #quality_metric: host=algo-1, epoch=3, train loss <loss>=10.839044666290283\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:56 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] Epoch[4] Batch[0] avg_epoch_loss=10.848954\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=10.848954200744629\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] Epoch[4] Batch[5] avg_epoch_loss=10.891296\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=10.891295750935873\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] Epoch[4] Batch [5]#011Speed: 1097.99 samples/sec#011loss=10.891296\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] Epoch[4] Batch[10] avg_epoch_loss=10.899258\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=10.90881290435791\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] Epoch[4] Batch [10]#011Speed: 1095.84 samples/sec#011loss=10.908813\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] processed a total of 329 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535656.9922757, \"EndTime\": 1733535657.3930056, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 400.35319328308105, \"count\": 1, \"min\": 400.35319328308105, \"max\": 400.35319328308105}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=821.5992250355897 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] #progress_metric: host=algo-1, completed 1.6666666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] #quality_metric: host=algo-1, epoch=4, train loss <loss>=10.899258093400435\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] Epoch[5] Batch[0] avg_epoch_loss=10.333965\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=10.333965301513672\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] Epoch[5] Batch[5] avg_epoch_loss=10.918232\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=10.918232440948486\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] Epoch[5] Batch [5]#011Speed: 826.42 samples/sec#011loss=10.918232\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] Epoch[5] Batch[10] avg_epoch_loss=10.912752\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=10.906176567077637\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] Epoch[5] Batch [10]#011Speed: 925.64 samples/sec#011loss=10.906177\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] processed a total of 331 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535657.393064, \"EndTime\": 1733535657.8892705, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 495.8677291870117, \"count\": 1, \"min\": 495.8677291870117, \"max\": 495.8677291870117}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=667.3861189187526 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] #progress_metric: host=algo-1, completed 2.0 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] #quality_metric: host=algo-1, epoch=5, train loss <loss>=10.912752498279918\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:57 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] Epoch[6] Batch[0] avg_epoch_loss=11.036935\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=11.036934852600098\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] Epoch[6] Batch[5] avg_epoch_loss=10.691131\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=10.691130956013998\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] Epoch[6] Batch [5]#011Speed: 792.05 samples/sec#011loss=10.691131\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] Epoch[6] Batch[10] avg_epoch_loss=10.840784\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=11.020368003845215\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] Epoch[6] Batch [10]#011Speed: 694.82 samples/sec#011loss=11.020368\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] processed a total of 323 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535657.8893352, \"EndTime\": 1733535658.4621658, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 572.4532604217529, \"count\": 1, \"min\": 572.4532604217529, \"max\": 572.4532604217529}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=564.1418724413928 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] #progress_metric: host=algo-1, completed 2.3333333333333335 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] #quality_metric: host=algo-1, epoch=6, train loss <loss>=10.840784159573642\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] Epoch[7] Batch[0] avg_epoch_loss=10.950233\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=10.950233459472656\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] Epoch[7] Batch[5] avg_epoch_loss=10.858207\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=10.858206590016684\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] Epoch[7] Batch [5]#011Speed: 820.93 samples/sec#011loss=10.858207\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] processed a total of 301 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535658.4622307, \"EndTime\": 1733535658.9631207, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 500.12755393981934, \"count\": 1, \"min\": 500.12755393981934, \"max\": 500.12755393981934}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=601.5003635247897 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] #progress_metric: host=algo-1, completed 2.6666666666666665 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] #quality_metric: host=algo-1, epoch=7, train loss <loss>=10.902642250061035\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:58 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:59 INFO 140215349077824] Epoch[8] Batch[0] avg_epoch_loss=10.803674\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:59 INFO 140215349077824] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=10.80367374420166\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:59 INFO 140215349077824] Epoch[8] Batch[5] avg_epoch_loss=10.792585\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:59 INFO 140215349077824] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=10.792585372924805\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:59 INFO 140215349077824] Epoch[8] Batch [5]#011Speed: 669.42 samples/sec#011loss=10.792585\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:59 INFO 140215349077824] Epoch[8] Batch[10] avg_epoch_loss=10.687875\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:59 INFO 140215349077824] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=10.562223625183105\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:59 INFO 140215349077824] Epoch[8] Batch [10]#011Speed: 932.30 samples/sec#011loss=10.562224\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:59 INFO 140215349077824] processed a total of 336 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535658.9633741, \"EndTime\": 1733535659.532706, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 568.4168338775635, \"count\": 1, \"min\": 568.4168338775635, \"max\": 568.4168338775635}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:59 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=591.0108863992351 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:59 INFO 140215349077824] #progress_metric: host=algo-1, completed 3.0 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:59 INFO 140215349077824] #quality_metric: host=algo-1, epoch=8, train loss <loss>=10.687875487587668\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:59 INFO 140215349077824] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:59 INFO 140215349077824] Saved checkpoint to \"/opt/ml/model/state_5efe04ca-7f07-4c35-b0b0-500e93b0f50f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535659.5327606, \"EndTime\": 1733535659.5415916, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 8.477449417114258, \"count\": 1, \"min\": 8.477449417114258, \"max\": 8.477449417114258}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:59 INFO 140215349077824] Epoch[9] Batch[0] avg_epoch_loss=10.731020\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:59 INFO 140215349077824] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=10.731019973754883\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:59 INFO 140215349077824] Epoch[9] Batch[5] avg_epoch_loss=10.614338\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:59 INFO 140215349077824] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=10.61433776219686\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:59 INFO 140215349077824] Epoch[9] Batch [5]#011Speed: 1000.51 samples/sec#011loss=10.614338\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:59 INFO 140215349077824] Epoch[9] Batch[10] avg_epoch_loss=10.727572\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:59 INFO 140215349077824] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=10.86345329284668\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:40:59 INFO 140215349077824] Epoch[9] Batch [10]#011Speed: 977.73 samples/sec#011loss=10.863453\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] processed a total of 359 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535659.541641, \"EndTime\": 1733535660.0034845, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 461.7929458618164, \"count\": 1, \"min\": 461.7929458618164, \"max\": 461.7929458618164}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=777.2429692206124 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] #progress_metric: host=algo-1, completed 3.3333333333333335 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] #quality_metric: host=algo-1, epoch=9, train loss <loss>=10.618029753367106\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] Saved checkpoint to \"/opt/ml/model/state_f5cea903-7cad-4e55-9b83-57f7f644c207-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535660.003548, \"EndTime\": 1733535660.0106568, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 6.702661514282227, \"count\": 1, \"min\": 6.702661514282227, \"max\": 6.702661514282227}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] Epoch[10] Batch[0] avg_epoch_loss=10.909676\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=10.909675598144531\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] Epoch[10] Batch[5] avg_epoch_loss=10.603974\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=10.603974183400473\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] Epoch[10] Batch [5]#011Speed: 971.55 samples/sec#011loss=10.603974\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] processed a total of 313 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535660.0107274, \"EndTime\": 1733535660.434878, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 424.09563064575195, \"count\": 1, \"min\": 424.09563064575195, \"max\": 424.09563064575195}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=737.8212481650252 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] #progress_metric: host=algo-1, completed 3.6666666666666665 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] #quality_metric: host=algo-1, epoch=10, train loss <loss>=10.798136138916016\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] Epoch[11] Batch[0] avg_epoch_loss=11.164750\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=11.164750099182129\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] Epoch[11] Batch[5] avg_epoch_loss=10.697057\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=10.697056929270426\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] Epoch[11] Batch [5]#011Speed: 969.44 samples/sec#011loss=10.697057\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] processed a total of 309 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535660.4349651, \"EndTime\": 1733535660.8402863, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 404.949426651001, \"count\": 1, \"min\": 404.949426651001, \"max\": 404.949426651001}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=762.8893638487524 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] #progress_metric: host=algo-1, completed 4.0 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] #quality_metric: host=algo-1, epoch=11, train loss <loss>=10.705146217346192\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] Epoch[12] Batch[0] avg_epoch_loss=10.485675\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:00 INFO 140215349077824] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=10.485674858093262\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] Epoch[12] Batch[5] avg_epoch_loss=10.784638\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=10.784637769063314\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] Epoch[12] Batch [5]#011Speed: 1066.98 samples/sec#011loss=10.784638\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] Epoch[12] Batch[10] avg_epoch_loss=10.604788\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=10.388967895507813\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] Epoch[12] Batch [10]#011Speed: 993.46 samples/sec#011loss=10.388968\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] processed a total of 357 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535660.8403463, \"EndTime\": 1733535661.287126, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 446.3634490966797, \"count\": 1, \"min\": 446.3634490966797, \"max\": 446.3634490966797}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=799.6326584668755 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] #progress_metric: host=algo-1, completed 4.333333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] #quality_metric: host=algo-1, epoch=12, train loss <loss>=10.639209270477295\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] Epoch[13] Batch[0] avg_epoch_loss=10.667369\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=10.66736888885498\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] Epoch[13] Batch[5] avg_epoch_loss=10.485589\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=10.485589027404785\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] Epoch[13] Batch [5]#011Speed: 1077.13 samples/sec#011loss=10.485589\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] Epoch[13] Batch[10] avg_epoch_loss=10.525155\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=10.572634506225587\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] Epoch[13] Batch [10]#011Speed: 1034.43 samples/sec#011loss=10.572635\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] processed a total of 327 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535661.287189, \"EndTime\": 1733535661.697002, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 409.52563285827637, \"count\": 1, \"min\": 409.52563285827637, \"max\": 409.52563285827637}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=798.315177760704 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] #progress_metric: host=algo-1, completed 4.666666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] #quality_metric: host=algo-1, epoch=13, train loss <loss>=10.525155154141514\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] Saved checkpoint to \"/opt/ml/model/state_1238926d-72c3-46b3-a2fb-7797115d2285-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535661.6970625, \"EndTime\": 1733535661.7037108, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 6.325244903564453, \"count\": 1, \"min\": 6.325244903564453, \"max\": 6.325244903564453}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] Epoch[14] Batch[0] avg_epoch_loss=10.933309\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=10.933308601379395\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] Epoch[14] Batch[5] avg_epoch_loss=10.624483\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=10.62448263168335\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:01 INFO 140215349077824] Epoch[14] Batch [5]#011Speed: 857.27 samples/sec#011loss=10.624483\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] Epoch[14] Batch[10] avg_epoch_loss=10.542545\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=10.444219970703125\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] Epoch[14] Batch [10]#011Speed: 847.67 samples/sec#011loss=10.444220\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] processed a total of 331 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535661.7037635, \"EndTime\": 1733535662.1856825, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 481.84967041015625, \"count\": 1, \"min\": 481.84967041015625, \"max\": 481.84967041015625}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=686.7707492069052 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] #quality_metric: host=algo-1, epoch=14, train loss <loss>=10.54254505851052\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] Epoch[15] Batch[0] avg_epoch_loss=10.630804\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=10.630804061889648\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] Epoch[15] Batch[5] avg_epoch_loss=10.768545\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=10.768545309702555\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] Epoch[15] Batch [5]#011Speed: 815.11 samples/sec#011loss=10.768545\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] Epoch[15] Batch[10] avg_epoch_loss=10.751474\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=10.730987739562988\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] Epoch[15] Batch [10]#011Speed: 736.31 samples/sec#011loss=10.730988\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] processed a total of 329 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535662.1857686, \"EndTime\": 1733535662.7316463, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 545.5148220062256, \"count\": 1, \"min\": 545.5148220062256, \"max\": 545.5148220062256}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=603.0035627185732 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] #progress_metric: host=algo-1, completed 5.333333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] #quality_metric: host=algo-1, epoch=15, train loss <loss>=10.751473686911844\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] Epoch[16] Batch[0] avg_epoch_loss=10.689868\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:02 INFO 140215349077824] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=10.689867973327637\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] Epoch[16] Batch[5] avg_epoch_loss=10.529784\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=10.529784202575684\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] Epoch[16] Batch [5]#011Speed: 1153.10 samples/sec#011loss=10.529784\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] Epoch[16] Batch[10] avg_epoch_loss=10.547253\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=10.568216514587402\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] Epoch[16] Batch [10]#011Speed: 776.47 samples/sec#011loss=10.568217\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] processed a total of 334 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535662.7317038, \"EndTime\": 1733535663.2086058, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 476.6058921813965, \"count\": 1, \"min\": 476.6058921813965, \"max\": 476.6058921813965}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=700.6396923161561 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] #progress_metric: host=algo-1, completed 5.666666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] #quality_metric: host=algo-1, epoch=16, train loss <loss>=10.547253435308283\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\n",
      "2024-12-07 01:40:46 Training - Training image download completed. Training in progress.\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] Epoch[17] Batch[0] avg_epoch_loss=10.679039\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=10.679039001464844\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] Epoch[17] Batch[5] avg_epoch_loss=10.612748\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=10.612748463948568\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] Epoch[17] Batch [5]#011Speed: 734.83 samples/sec#011loss=10.612748\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] Epoch[17] Batch[10] avg_epoch_loss=10.682207\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=10.765557670593262\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] Epoch[17] Batch [10]#011Speed: 752.32 samples/sec#011loss=10.765558\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] processed a total of 322 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535663.2086742, \"EndTime\": 1733535663.7919607, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 583.0440521240234, \"count\": 1, \"min\": 583.0440521240234, \"max\": 583.0440521240234}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=552.1659499693778 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] #progress_metric: host=algo-1, completed 6.0 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] #quality_metric: host=algo-1, epoch=17, train loss <loss>=10.682207194241611\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] Epoch[18] Batch[0] avg_epoch_loss=11.008043\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:03 INFO 140215349077824] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=11.00804328918457\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] Epoch[18] Batch[5] avg_epoch_loss=10.799694\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=10.799694220225016\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] Epoch[18] Batch [5]#011Speed: 1113.31 samples/sec#011loss=10.799694\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] Epoch[18] Batch[10] avg_epoch_loss=10.613473\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=10.390007591247558\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] Epoch[18] Batch [10]#011Speed: 1079.59 samples/sec#011loss=10.390008\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] processed a total of 332 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535663.7920241, \"EndTime\": 1733535664.2021613, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 409.4250202178955, \"count\": 1, \"min\": 409.4250202178955, \"max\": 409.4250202178955}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=810.6931210000483 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] #progress_metric: host=algo-1, completed 6.333333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] #quality_metric: host=algo-1, epoch=18, train loss <loss>=10.613473025235264\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] Epoch[19] Batch[0] avg_epoch_loss=10.561612\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=10.561612129211426\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] Epoch[19] Batch[5] avg_epoch_loss=10.572058\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=10.572058041890463\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] Epoch[19] Batch [5]#011Speed: 1140.23 samples/sec#011loss=10.572058\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] processed a total of 310 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535664.2022297, \"EndTime\": 1733535664.5621874, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 359.56501960754395, \"count\": 1, \"min\": 359.56501960754395, \"max\": 359.56501960754395}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=861.8448110381105 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] #progress_metric: host=algo-1, completed 6.666666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] #quality_metric: host=algo-1, epoch=19, train loss <loss>=10.601932811737061\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] Epoch[20] Batch[0] avg_epoch_loss=10.714252\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=10.714252471923828\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] Epoch[20] Batch[5] avg_epoch_loss=10.687357\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=10.687357425689697\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] Epoch[20] Batch [5]#011Speed: 916.58 samples/sec#011loss=10.687357\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] processed a total of 297 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535664.5622466, \"EndTime\": 1733535664.9697013, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 406.965970993042, \"count\": 1, \"min\": 406.965970993042, \"max\": 406.965970993042}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=729.5620829365483 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] #progress_metric: host=algo-1, completed 7.0 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] #quality_metric: host=algo-1, epoch=20, train loss <loss>=10.461315441131593\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:04 INFO 140215349077824] Saved checkpoint to \"/opt/ml/model/state_53a59c24-43d6-418d-9a7b-ee0f7e021312-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535664.9697952, \"EndTime\": 1733535664.9771254, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 6.721735000610352, \"count\": 1, \"min\": 6.721735000610352, \"max\": 6.721735000610352}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] Epoch[21] Batch[0] avg_epoch_loss=10.399998\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=10.39999771118164\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] Epoch[21] Batch[5] avg_epoch_loss=10.616261\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=10.616260846455893\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] Epoch[21] Batch [5]#011Speed: 1019.59 samples/sec#011loss=10.616261\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] processed a total of 313 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535664.9771814, \"EndTime\": 1733535665.3571367, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 379.9018859863281, \"count\": 1, \"min\": 379.9018859863281, \"max\": 379.9018859863281}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=823.67259316702 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] #progress_metric: host=algo-1, completed 7.333333333333333 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] #quality_metric: host=algo-1, epoch=21, train loss <loss>=10.661134719848633\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] Epoch[22] Batch[0] avg_epoch_loss=10.601258\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=10.601258277893066\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] Epoch[22] Batch[5] avg_epoch_loss=10.613352\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=10.613351504007975\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] Epoch[22] Batch [5]#011Speed: 1162.29 samples/sec#011loss=10.613352\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] processed a total of 313 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535665.3572092, \"EndTime\": 1733535665.7215629, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 364.0580177307129, \"count\": 1, \"min\": 364.0580177307129, \"max\": 364.0580177307129}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=859.5070940489339 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] #progress_metric: host=algo-1, completed 7.666666666666667 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] #quality_metric: host=algo-1, epoch=22, train loss <loss>=10.631039905548096\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] Epoch[23] Batch[0] avg_epoch_loss=11.022734\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=11.022733688354492\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] Epoch[23] Batch[5] avg_epoch_loss=10.699276\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=10.699275970458984\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:05 INFO 140215349077824] Epoch[23] Batch [5]#011Speed: 1118.62 samples/sec#011loss=10.699276\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] Epoch[23] Batch[10] avg_epoch_loss=10.663592\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=10.620771408081055\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] Epoch[23] Batch [10]#011Speed: 1070.16 samples/sec#011loss=10.620771\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] processed a total of 349 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535665.7216341, \"EndTime\": 1733535666.1242552, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 402.1649360656738, \"count\": 1, \"min\": 402.1649360656738, \"max\": 402.1649360656738}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=867.6107863080082 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] #progress_metric: host=algo-1, completed 8.0 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] #quality_metric: host=algo-1, epoch=23, train loss <loss>=10.663592078469016\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] Epoch[24] Batch[0] avg_epoch_loss=10.267442\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=10.267441749572754\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] Epoch[24] Batch[5] avg_epoch_loss=10.684863\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=10.684862931569418\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] Epoch[24] Batch [5]#011Speed: 1129.45 samples/sec#011loss=10.684863\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] Epoch[24] Batch[10] avg_epoch_loss=10.662363\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=10.635363578796387\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] Epoch[24] Batch [10]#011Speed: 1071.58 samples/sec#011loss=10.635364\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] processed a total of 330 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535666.1243148, \"EndTime\": 1733535666.5255353, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 400.94995498657227, \"count\": 1, \"min\": 400.94995498657227, \"max\": 400.94995498657227}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=822.8736124875674 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] #progress_metric: host=algo-1, completed 8.333333333333334 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] #quality_metric: host=algo-1, epoch=24, train loss <loss>=10.662363225763494\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] Epoch[25] Batch[0] avg_epoch_loss=10.259304\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=10.25930404663086\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] Epoch[25] Batch[5] avg_epoch_loss=10.757769\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=10.757769266764322\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] Epoch[25] Batch [5]#011Speed: 1122.79 samples/sec#011loss=10.757769\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] processed a total of 312 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535666.525592, \"EndTime\": 1733535666.9038582, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 377.7639865875244, \"count\": 1, \"min\": 377.7639865875244, \"max\": 377.7639865875244}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=825.7160358750507 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] #progress_metric: host=algo-1, completed 8.666666666666666 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] #quality_metric: host=algo-1, epoch=25, train loss <loss>=10.615369892120361\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:06 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] Epoch[26] Batch[0] avg_epoch_loss=10.734373\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=10.734373092651367\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] Epoch[26] Batch[5] avg_epoch_loss=10.642734\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=10.642734050750732\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] Epoch[26] Batch [5]#011Speed: 1090.24 samples/sec#011loss=10.642734\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] processed a total of 314 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535666.9039195, \"EndTime\": 1733535667.2754514, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 371.09899520874023, \"count\": 1, \"min\": 371.09899520874023, \"max\": 371.09899520874023}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=845.9294294168918 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] #progress_metric: host=algo-1, completed 9.0 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] #quality_metric: host=algo-1, epoch=26, train loss <loss>=10.603717708587647\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] Epoch[27] Batch[0] avg_epoch_loss=10.332698\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=10.332697868347168\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] Epoch[27] Batch[5] avg_epoch_loss=10.492689\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=10.492688655853271\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] Epoch[27] Batch [5]#011Speed: 1028.40 samples/sec#011loss=10.492689\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] processed a total of 316 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535667.2755113, \"EndTime\": 1733535667.6649444, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 389.1448974609375, \"count\": 1, \"min\": 389.1448974609375, \"max\": 389.1448974609375}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=811.8130392333408 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] #progress_metric: host=algo-1, completed 9.333333333333334 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] #quality_metric: host=algo-1, epoch=27, train loss <loss>=10.55689754486084\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] Epoch[28] Batch[0] avg_epoch_loss=10.333257\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=10.333256721496582\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] Epoch[28] Batch[5] avg_epoch_loss=10.511618\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=10.511617501576742\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:07 INFO 140215349077824] Epoch[28] Batch [5]#011Speed: 1054.35 samples/sec#011loss=10.511618\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] Epoch[28] Batch[10] avg_epoch_loss=10.471166\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=10.422624397277833\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] Epoch[28] Batch [10]#011Speed: 1089.66 samples/sec#011loss=10.422624\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] processed a total of 323 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535667.6650045, \"EndTime\": 1733535668.068886, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 403.56969833374023, \"count\": 1, \"min\": 403.56969833374023, \"max\": 403.56969833374023}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=800.1021666231602 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] #progress_metric: host=algo-1, completed 9.666666666666666 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] #quality_metric: host=algo-1, epoch=28, train loss <loss>=10.471166090531783\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] Epoch[29] Batch[0] avg_epoch_loss=10.597017\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=10.597017288208008\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] Epoch[29] Batch[5] avg_epoch_loss=10.573028\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=10.573028405507406\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] Epoch[29] Batch [5]#011Speed: 1045.05 samples/sec#011loss=10.573028\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] Epoch[29] Batch[10] avg_epoch_loss=10.368275\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=10.12257194519043\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] Epoch[29] Batch [10]#011Speed: 1013.05 samples/sec#011loss=10.122572\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] processed a total of 349 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535668.068986, \"EndTime\": 1733535668.4841216, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 414.86597061157227, \"count\": 1, \"min\": 414.86597061157227, \"max\": 414.86597061157227}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=841.0586380455517 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] #quality_metric: host=algo-1, epoch=29, train loss <loss>=10.36827546899969\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] Saved checkpoint to \"/opt/ml/model/state_f03a87ed-ec88-4e6e-b82b-abd4ee9d42a1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535668.4841805, \"EndTime\": 1733535668.4910843, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.serialize.time\": {\"sum\": 6.368160247802734, \"count\": 1, \"min\": 6.368160247802734, \"max\": 6.368160247802734}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] Epoch[30] Batch[0] avg_epoch_loss=11.009487\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=11.00948715209961\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] Epoch[30] Batch[5] avg_epoch_loss=10.693042\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=10.693042437235514\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] Epoch[30] Batch [5]#011Speed: 951.70 samples/sec#011loss=10.693042\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] processed a total of 320 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535668.4911335, \"EndTime\": 1733535668.8846507, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 393.47267150878906, \"count\": 1, \"min\": 393.47267150878906, \"max\": 393.47267150878906}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=813.0849894773318 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] #progress_metric: host=algo-1, completed 10.333333333333334 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] #quality_metric: host=algo-1, epoch=30, train loss <loss>=10.650991344451905\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] Epoch[31] Batch[0] avg_epoch_loss=10.885234\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:08 INFO 140215349077824] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=10.885233879089355\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] Epoch[31] Batch[5] avg_epoch_loss=10.500447\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=10.500447273254395\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] Epoch[31] Batch [5]#011Speed: 1082.90 samples/sec#011loss=10.500447\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] processed a total of 303 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535668.8847106, \"EndTime\": 1733535669.2594893, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 374.2940425872803, \"count\": 1, \"min\": 374.2940425872803, \"max\": 374.2940425872803}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=809.2976638210021 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] #progress_metric: host=algo-1, completed 10.666666666666666 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] #quality_metric: host=algo-1, epoch=31, train loss <loss>=10.657906341552735\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] Epoch[32] Batch[0] avg_epoch_loss=10.528502\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=10.528502464294434\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] Epoch[32] Batch[5] avg_epoch_loss=10.500360\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=10.500359694163004\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] Epoch[32] Batch [5]#011Speed: 1124.28 samples/sec#011loss=10.500360\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] processed a total of 285 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535669.2595613, \"EndTime\": 1733535669.5936558, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 333.6334228515625, \"count\": 1, \"min\": 333.6334228515625, \"max\": 333.6334228515625}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=853.9825842443778 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] #progress_metric: host=algo-1, completed 11.0 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] #quality_metric: host=algo-1, epoch=32, train loss <loss>=10.506171650356716\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] Epoch[33] Batch[0] avg_epoch_loss=10.697405\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=10.697404861450195\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] Epoch[33] Batch[5] avg_epoch_loss=10.510227\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=10.510227044423422\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:09 INFO 140215349077824] Epoch[33] Batch [5]#011Speed: 1090.13 samples/sec#011loss=10.510227\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] Epoch[33] Batch[10] avg_epoch_loss=10.585591\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=10.676027297973633\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] Epoch[33] Batch [10]#011Speed: 875.45 samples/sec#011loss=10.676027\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] processed a total of 344 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535669.5937243, \"EndTime\": 1733535670.031422, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 437.21914291381836, \"count\": 1, \"min\": 437.21914291381836, \"max\": 437.21914291381836}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=786.6308014979803 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] #progress_metric: host=algo-1, completed 11.333333333333334 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] #quality_metric: host=algo-1, epoch=33, train loss <loss>=10.585590796037154\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] Epoch[34] Batch[0] avg_epoch_loss=10.491114\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=10.491113662719727\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] Epoch[34] Batch[5] avg_epoch_loss=10.593142\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=10.593141873677572\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] Epoch[34] Batch [5]#011Speed: 1162.29 samples/sec#011loss=10.593142\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] Epoch[34] Batch[10] avg_epoch_loss=10.381910\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=10.128431701660157\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] Epoch[34] Batch [10]#011Speed: 995.19 samples/sec#011loss=10.128432\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] processed a total of 337 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535670.0314825, \"EndTime\": 1733535670.437311, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 405.4703712463379, \"count\": 1, \"min\": 405.4703712463379, \"max\": 405.4703712463379}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=830.9551372079638 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] #progress_metric: host=algo-1, completed 11.666666666666666 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] #quality_metric: host=algo-1, epoch=34, train loss <loss>=10.38190997730602\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] Epoch[35] Batch[0] avg_epoch_loss=10.364943\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=10.36494255065918\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] Epoch[35] Batch[5] avg_epoch_loss=10.452868\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=10.45286750793457\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] Epoch[35] Batch [5]#011Speed: 1038.59 samples/sec#011loss=10.452868\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] Epoch[35] Batch[10] avg_epoch_loss=10.564601\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=10.69868049621582\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] Epoch[35] Batch [10]#011Speed: 1031.99 samples/sec#011loss=10.698680\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] processed a total of 327 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535670.4373693, \"EndTime\": 1733535670.8591855, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 421.54788970947266, \"count\": 1, \"min\": 421.54788970947266, \"max\": 421.54788970947266}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=775.51432358223 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] #progress_metric: host=algo-1, completed 12.0 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] #quality_metric: host=algo-1, epoch=35, train loss <loss>=10.564600684426047\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] Epoch[36] Batch[0] avg_epoch_loss=10.374027\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:10 INFO 140215349077824] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=10.374027252197266\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] Epoch[36] Batch[5] avg_epoch_loss=10.547497\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=10.547497272491455\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] Epoch[36] Batch [5]#011Speed: 1037.05 samples/sec#011loss=10.547497\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] Epoch[36] Batch[10] avg_epoch_loss=10.555315\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=10.564697074890137\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] Epoch[36] Batch [10]#011Speed: 969.18 samples/sec#011loss=10.564697\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] processed a total of 341 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535670.8592582, \"EndTime\": 1733535671.290867, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 431.20265007019043, \"count\": 1, \"min\": 431.20265007019043, \"max\": 431.20265007019043}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=790.619122349761 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] #progress_metric: host=algo-1, completed 12.333333333333334 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] #quality_metric: host=algo-1, epoch=36, train loss <loss>=10.555315364490856\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] Epoch[37] Batch[0] avg_epoch_loss=10.222937\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=10.222936630249023\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] Epoch[37] Batch[5] avg_epoch_loss=10.658599\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=10.65859858194987\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] Epoch[37] Batch [5]#011Speed: 1069.85 samples/sec#011loss=10.658599\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] Epoch[37] Batch[10] avg_epoch_loss=10.604482\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=10.53954200744629\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] Epoch[37] Batch [10]#011Speed: 1022.71 samples/sec#011loss=10.539542\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] processed a total of 338 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535671.2909374, \"EndTime\": 1733535671.7100694, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 418.597936630249, \"count\": 1, \"min\": 418.597936630249, \"max\": 418.597936630249}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=807.2601477317505 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] #progress_metric: host=algo-1, completed 12.666666666666666 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] #quality_metric: host=algo-1, epoch=37, train loss <loss>=10.604481957175516\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] Epoch[38] Batch[0] avg_epoch_loss=9.956745\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=9.956745147705078\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] Epoch[38] Batch[5] avg_epoch_loss=10.424778\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=10.42477798461914\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:11 INFO 140215349077824] Epoch[38] Batch [5]#011Speed: 1072.40 samples/sec#011loss=10.424778\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] Epoch[38] Batch[10] avg_epoch_loss=10.588180\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=10.78426284790039\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] Epoch[38] Batch [10]#011Speed: 1054.77 samples/sec#011loss=10.784263\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] processed a total of 335 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535671.7101374, \"EndTime\": 1733535672.1273966, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 416.8393611907959, \"count\": 1, \"min\": 416.8393611907959, \"max\": 416.8393611907959}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=803.4885937810045 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] #progress_metric: host=algo-1, completed 13.0 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] #quality_metric: host=algo-1, epoch=38, train loss <loss>=10.588180195201527\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] Epoch[39] Batch[0] avg_epoch_loss=10.741434\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=10.741434097290039\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] Epoch[39] Batch[5] avg_epoch_loss=10.600815\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=10.600815455118815\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] Epoch[39] Batch [5]#011Speed: 1084.95 samples/sec#011loss=10.600815\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] Epoch[39] Batch[10] avg_epoch_loss=10.566531\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=10.525389289855957\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] Epoch[39] Batch [10]#011Speed: 1006.70 samples/sec#011loss=10.525389\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] processed a total of 353 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535672.1274571, \"EndTime\": 1733535672.574922, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 446.97070121765137, \"count\": 1, \"min\": 446.97070121765137, \"max\": 446.97070121765137}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] #throughput_metric: host=algo-1, train throughput=789.5773080477633 records/second\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] #progress_metric: host=algo-1, completed 13.333333333333334 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] #quality_metric: host=algo-1, epoch=39, train loss <loss>=10.54981517791748\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] loss did not improve\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] Loading parameters from best epoch (29)\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535672.5749831, \"EndTime\": 1733535672.5788634, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"state.deserialize.time\": {\"sum\": 3.3774375915527344, \"count\": 1, \"min\": 3.3774375915527344, \"max\": 3.3774375915527344}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] stopping training now\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] Final loss: 10.36827546899969 (occurred at epoch 29)\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] #quality_metric: host=algo-1, train final_loss <loss>=10.36827546899969\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 WARNING 140215349077824] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535672.578912, \"EndTime\": 1733535672.6284282, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"get_graph.time\": {\"sum\": 48.96426200866699, \"count\": 1, \"min\": 48.96426200866699, \"max\": 48.96426200866699}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535672.6284764, \"EndTime\": 1733535672.6461987, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 66.76459312438965, \"count\": 1, \"min\": 66.76459312438965, \"max\": 66.76459312438965}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535672.6462474, \"EndTime\": 1733535672.6494834, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 3.2019615173339844, \"count\": 1, \"min\": 3.2019615173339844, \"max\": 3.2019615173339844}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] #memory_usage::<batchbuffer> = 0.89111328125 mb\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:12 INFO 140215349077824] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535672.6495225, \"EndTime\": 1733535672.6531503, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.bind.time\": {\"sum\": 0.031948089599609375, \"count\": 1, \"min\": 0.031948089599609375, \"max\": 0.031948089599609375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535672.6531906, \"EndTime\": 1733535673.043759, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.score.time\": {\"sum\": 390.6407356262207, \"count\": 1, \"min\": 390.6407356262207, \"max\": 390.6407356262207}}}\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:13 INFO 140215349077824] #test_score (algo-1, RMSE): 24473.544440004734\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:13 INFO 140215349077824] #test_score (algo-1, mean_absolute_QuantileLoss): 4928300.079039849\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:13 INFO 140215349077824] #test_score (algo-1, mean_wQuantileLoss): 0.26110586430102534\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:13 INFO 140215349077824] #test_score (algo-1, wQuantileLoss[0.1]): 0.24613481613136282\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:13 INFO 140215349077824] #test_score (algo-1, wQuantileLoss[0.2]): 0.3568110471524959\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:13 INFO 140215349077824] #test_score (algo-1, wQuantileLoss[0.3]): 0.39174193188588885\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:13 INFO 140215349077824] #test_score (algo-1, wQuantileLoss[0.4]): 0.35813626911507046\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:13 INFO 140215349077824] #test_score (algo-1, wQuantileLoss[0.5]): 0.27564149777163915\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:13 INFO 140215349077824] #test_score (algo-1, wQuantileLoss[0.6]): 0.18093409405388283\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:13 INFO 140215349077824] #test_score (algo-1, wQuantileLoss[0.7]): 0.1793692570443595\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:13 INFO 140215349077824] #test_score (algo-1, wQuantileLoss[0.8]): 0.1947984889627874\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:13 INFO 140215349077824] #test_score (algo-1, wQuantileLoss[0.9]): 0.1663853765917413\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:13 INFO 140215349077824] #quality_metric: host=algo-1, test RMSE <loss>=24473.544440004734\u001b[0m\n",
      "\u001b[34m[12/07/2024 01:41:13 INFO 140215349077824] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.26110586430102534\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1733535673.0438278, \"EndTime\": 1733535673.0514708, \"Dimensions\": {\"Algorithm\": \"AWS/DeepAR\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 3.872394561767578, \"count\": 1, \"min\": 3.872394561767578, \"max\": 3.872394561767578}, \"totaltime\": {\"sum\": 18021.448135375977, \"count\": 1, \"min\": 18021.448135375977, \"max\": 18021.448135375977}}}\u001b[0m\n",
      "\n",
      "2024-12-07 01:41:34 Uploading - Uploading generated training model\n",
      "2024-12-07 01:41:34 Completed - Training job completed\n",
      "Training seconds: 200\n",
      "Billable seconds: 200\n"
     ]
    }
   ],
   "source": [
    "data_channels = {\"train\": train_path, \"test\": test_path}\n",
    "deepAR.fit(inputs=data_channels, wait=True, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: forecasting-deepar-2024-12-07-01-42-35-490\n",
      "INFO:sagemaker:Creating endpoint-config with name forecasting-deepar-2024-12-07-01-42-35-490\n",
      "INFO:sagemaker:Creating endpoint with name forecasting-deepar-2024-12-07-01-42-35-490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "deepAR_predictor = deepAR.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consume Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sales:  [65935.3671875, 78077.0703125, 63357.61328125, 62673.828125, 74889.03125, 83905.4375, 90564.859375, 75975.2578125, 91030.078125]\n",
      "Actual Sales:  [100422.86, 94987.08, 90889.75, 115695.71, 100372.02, 96616.19, 93460.57, 99398.64, 105059.88]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Predict last 9 weeks of a department and compare to ground truth\n",
    "\n",
    "deepAR_predictor.content_type = 'application/json'\n",
    "dept = 90 \n",
    "\n",
    "prediction_data = da.salesinference.buildInferenceData(dept, trainingSet, testSet)\n",
    "#print(prediction_data)\n",
    "\n",
    "result = deepAR_predictor.predict(prediction_data)\n",
    "\n",
    "y_mean, y_q1, y_q2, y_sample = da.salesinference.getInferenceSeries(result)\n",
    "print(\"Predicted Sales: \", y_mean)\n",
    "print(\"Actual Sales: \", list(testSet[dept]['Weekly_Sales'][134:]))\n",
    "\n",
    "da.salesinference.plotResults(prediction_length, result, truth=True, truth_data=testSet[dept]['Weekly_Sales'][134:], truth_label='truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
